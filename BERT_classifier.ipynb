{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUOy0TKt7WkA"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "%cd 'drive/MyDrive/'\n",
        "\n",
        "!export BERT_BASE_DIR=Internship/BERT/BERT-mini\n",
        "!export DATA_DIR=Internship/Data/binary\n",
        "\n",
        "!python Internship/BERT/run_classifier.py \\\n",
        "  --task_name=GPT_Classifier \\\n",
        "  --do_train=true \\\n",
        "  --do_eval=true \\\n",
        "  --data_dir=$DATA_DIR/\\\n",
        "  --vocab_file=Internship/BERT/BERT-mini/vocab.txt \\\n",
        "  --bert_config_file=Internship/BERT/BERT-mini/bert_config.json \\\n",
        "  --init_checkpoint=Internship/BERT/BERT-mini/bert_model.ckpt \\\n",
        "  --max_seq_length=512 \\\n",
        "  --train_batch_size=32 \\\n",
        "  --learning_rate=2e-5 \\\n",
        "  --num_train_epochs=15 \\\n",
        "  --output_dir=$DATA_DIR/output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YslA20V0HhbP"
      },
      "source": [
        "!pip3 install transformers numpy torch sklearn\n",
        "\n",
        "# this cell imports the data, trains the BERT model and saves it\n",
        "\n",
        "import torch\n",
        "from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification, AutoTokenizer\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "%cd 'drive/MyDrive/Internship/Data'\n",
        "\n",
        "temps = [\"0_5\", \"0_75\", \"1_0\", \"1_25\", \"1_5\"]\n",
        "file_names = [\"CNNArticles\", \"fb_edit\", \"ireland_headlines\", \"tweets_edited\"]\n",
        "\n",
        "\n",
        "model_name = \"prajjwal1/bert-medium\"\n",
        "max_length = 512\n",
        "\n",
        "#tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True, use_fast=False)\n",
        "\n",
        "model_path = \"gpt_classifier\"\n",
        "#tokenizer.save_pretrained(model_path)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "def compute_acc(pred):\n",
        "\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {\n",
        "      'accuracy': acc,\n",
        "  }\n",
        "\n",
        "def read_data():\n",
        "\n",
        "    gpt_data = pd.read_csv(\"train_data/gpt_text.csv\")\n",
        "    human_data = pd.read_csv(\"train_data/human_text.csv\")\n",
        "\n",
        "    gpt_text = list(gpt_data.iloc[:, 0])\n",
        "    human_text = list(human_data.iloc[:, 0])\n",
        "\n",
        "    # get test data\n",
        "\n",
        "    with open(\"test_data/test_data.pkl\", \"rb\") as f:\n",
        "\n",
        "        test_data = pickle.load(f)\n",
        "\n",
        "    test_labels = []\n",
        "    test_text = []\n",
        "\n",
        "    print(test_data[(\"CNNArticles\", \"0_5\")])\n",
        "\n",
        "    test_human_len = 0\n",
        "    test_gpt_len = 0\n",
        "\n",
        "    for f in file_names:\n",
        "\n",
        "        for t in temps:\n",
        "\n",
        "            a = list(test_data[(f,t)].iloc[:, 0])\n",
        "            test_text = test_text + a\n",
        "            test_labels = test_labels + list(np.ones(len(test_data[(f,t)]), dtype=int))\n",
        "            test_gpt_len += len(a)\n",
        "\n",
        "    for f in file_names:\n",
        "\n",
        "        a = list(test_data[f].iloc[:,0])\n",
        "        test_text = test_text + a\n",
        "        test_labels = test_labels + list(np.zeros(len(test_data[f]), dtype=int))\n",
        "\n",
        "        test_human_len += len(a)\n",
        "\n",
        "    # format train data\n",
        "\n",
        "    train_text = gpt_text + human_text\n",
        "\n",
        "    print(len(gpt_text))\n",
        "    print(len(human_text))\n",
        "    print(test_human_len)\n",
        "    print(test_gpt_len)\n",
        "\n",
        "    train_labels = list(np.ones(len(gpt_text), dtype=int)) + list(np.zeros(len(human_text), dtype=int))\n",
        "\n",
        "    return train_text, test_text, train_labels, test_labels\n",
        "\n",
        "\n",
        "(train_text, test_text, train_labels, test_labels)= read_data()\n",
        "\n",
        "\n",
        "print(len(train_text))\n",
        "print(len(test_text))\n",
        "print(len(train_labels))\n",
        "print(len(test_labels))\n",
        "\n",
        "for i, t in enumerate(train_text):\n",
        "\n",
        "  if type(t) != str:\n",
        "\n",
        "    train_text[i] = \" \"\n",
        "\n",
        "\n",
        "for i, t in enumerate(test_text):\n",
        "\n",
        "  if type(t) != str:\n",
        "\n",
        "    test_text[i] = \" \"\n",
        "\n",
        "shuffling = list(zip(train_text, train_labels))\n",
        "random.shuffle(shuffling)\n",
        "train_text, train_labels = zip(*shuffling)\n",
        "\n",
        "train_text = list(train_text)\n",
        "train_labels = list(train_labels)\n",
        "\n",
        "\n",
        "print(train_text[1:10])\n",
        "print(train_labels[1:10])\n",
        "\n",
        "train_encoding = tokenizer(text=train_text, truncation=True, padding=True, max_length=max_length)\n",
        "test_encoding = tokenizer(text=test_text, truncation=True, padding=True, max_length=max_length)\n",
        "\n",
        "class TextDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "train_dataset = TextDataset(train_encoding, train_labels)\n",
        "test_dataset = TextDataset(test_encoding, test_labels)\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2).to(\"cuda\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=20,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    learning_rate=5e-5,\n",
        "    logging_dir='./logs',\n",
        "    load_best_model_at_end=True,\n",
        "    logging_steps=300,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    gradient_accumulation_steps=16\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_acc,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "trainer.evaluate()\n",
        "\n",
        "\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX72u48j-dH-"
      },
      "source": [
        "# evaluate BERT model on subsets of data\n",
        "\n",
        "!pip3 install transformers numpy torch sklearn\n",
        "\n",
        "from transformers import BertConfig, BertModel\n",
        "from google.colab import drive\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification, AutoTokenizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "%cd 'drive/MyDrive/Internship/Data'\n",
        "\n",
        "model_path = \"gpt_classifier\"\n",
        "max_length = 512\n",
        "\n",
        "temps = [\"0_5\", \"0_75\", \"1_0\", \"1_25\", \"1_5\"]\n",
        "file_names = [\"CNNArticles\", \"fb_edit\", \"ireland_headlines\", \"tweets_edited\"]\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(model_path).to(\"cuda\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "with open(\"test_data/test_data.pkl\", \"rb\") as f:\n",
        "\n",
        "    test_data = pickle.load(f)\n",
        "\n",
        "def get_prediction(text):\n",
        "\n",
        "    try:\n",
        "\n",
        "      inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    except:\n",
        "\n",
        "      print(text)\n",
        "\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    probs = outputs[0].softmax(1)\n",
        "\n",
        "    return probs.argmax()\n",
        "\n",
        "\n",
        "for f in file_names:\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for t in temps:\n",
        "\n",
        "        a = list(test_data[(f, t)].iloc[:, 0].dropna())\n",
        "\n",
        "        x = x + a\n",
        "        y = y + list(np.ones(len(a), dtype=int))\n",
        "\n",
        "    a = list(test_data[f].iloc[:, 0].dropna())\n",
        "\n",
        "    x = x + a\n",
        "    y = y + list(np.zeros(len(a), dtype=int))\n",
        "\n",
        "    y_hat = [int(get_prediction(i)) for i in x]\n",
        "\n",
        "    print(y_hat[1:10])\n",
        "    print(f)\n",
        "    print(accuracy_score(y, y_hat))\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_fBfbhnBjnC",
        "outputId": "3734f991-a77c-44ab-b700-b807d2c96f1e"
      },
      "source": [
        "[1,2,3] == [1,0,1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "RkPEdefbysW7",
        "outputId": "ba1be1b9-dfab-4484-9faf-8e4ad46c854e"
      },
      "source": [
        "print(test_data[(\"CNNArticles\", \"0_5\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4163e9e552fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CNNArticles\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"0_5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gi6Ep76jD_V"
      },
      "source": [
        "for i in train_text:\n",
        "\n",
        "  if type(i) != str:\n",
        "\n",
        "    print(type(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epv8zlZn4X8U"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import pickle\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "%cd 'drive/MyDrive/Internship/Data'\n",
        "\n",
        "temps = [\"0_5\", \"0_75\", \"1_0\", \"1_25\", \"1_5\"]\n",
        "file_names = [\"CNNArticles\", \"fb_edit\", \"ireland_headlines\", \"tweets_edited\"]\n",
        "\n",
        "gpt_train_list = []\n",
        "human_train_list = []\n",
        "\n",
        "test_data = {}\n",
        "\n",
        "# training data and test data (divided by temperature and corpus)\n",
        "\n",
        "for f in file_names:\n",
        "\n",
        "  for t in temps:\n",
        "\n",
        "    df = pd.read_csv(\"gpt/\" + f + t + \".csv\", engine='python', error_bad_lines=False)\n",
        "\n",
        "    if t == \"1_0\":\n",
        "\n",
        "        indices = np.random.choice(range(df.shape[0]), 10000, replace=False)\n",
        "\n",
        "    else:\n",
        "\n",
        "        indices = np.random.choice(range(df.shape[0]), min(df.shape[0],2000), replace=False)\n",
        "\n",
        "    df = df.iloc[indices, :]\n",
        "\n",
        "    for i in range(df.shape[0]):\n",
        "\n",
        "      df.iloc[i, 0] = df.iloc[i, 0].replace(\"<|startoftext|>\", \"\")\n",
        "\n",
        "    test_indices = np.random.choice(range(df.shape[0]), int(df.shape[0]*0.2), replace=False)\n",
        "    train_indices = list(set(range(df.shape[0])) - set(test_indices))\n",
        "\n",
        "\n",
        "    gpt_train_list.append(df.iloc[train_indices, :])\n",
        "\n",
        "    test_data[(f, t)] = df.iloc[test_indices, :]\n",
        "\n",
        "for f in file_names:\n",
        "\n",
        "\n",
        "    df = pd.read_csv(\"human/\" + f + \".csv\")\n",
        "\n",
        "    indices = np.random.choice(range(df.shape[0]), 18000, replace=False)\n",
        "\n",
        "    df = df.iloc[indices, :]\n",
        "\n",
        "    test_indices = np.random.choice(range(df.shape[0]), int(df.shape[0]*0.2), replace=False)\n",
        "    train_indices = list(set(range(df.shape[0])) - set(test_indices))\n",
        "\n",
        "    human_train_list.append(df.iloc[train_indices, :])\n",
        "\n",
        "    test_data[f] = df.iloc[test_indices, :]\n",
        "\n",
        "\n",
        "gpt_df = pd.concat(gpt_train_list)\n",
        "human_df = pd.concat(human_train_list)\n",
        "\n",
        "gpt_df.to_csv(\"train_data/gpt_text.csv\", index = False)\n",
        "human_df.to_csv(\"train_data/human_text.csv\", index = False)\n",
        "\n",
        "a = gpt_df.shape[0]\n",
        "b = human_df.shape[0]\n",
        "\n",
        "indices = np.random.choice(min(a,b), size=1000, replace=False)\n",
        "\n",
        "gpt_df.iloc[indices, :].to_csv(\"test_gpt.csv\", index=False)\n",
        "human_df.iloc[indices, :].to_csv(\"test_human.csv\", index=False)\n",
        "\n",
        "\n",
        "with open(\"test_data/test_data.pkl\", \"wb\") as f:\n",
        "\n",
        "    pickle.dump(test_data, f)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZxXLJcfYvBj"
      },
      "source": [
        "# testing that pickled test data saved correctly\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "%cd 'drive/MyDrive/Internship/Data'\n",
        "\n",
        "with open(\"test_data/test_data.pkl\", \"rb\") as f:\n",
        "\n",
        "    test_data = pickle.load(f)\n",
        "\n",
        "print(test_data.keys())\n",
        "\n",
        "print(test_data[\"ireland_headlines\"])\n",
        "print(test_data[(\"CNNArticles\", \"0_75\")])\n",
        "\n",
        "for i in test_data.keys():\n",
        "\n",
        "  print(test_data[i].shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NirVveR12RWf"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aTq4XHcWLYJ",
        "outputId": "e30ffb2f-686f-4fb2-c7b1-fde9ce5b9464"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "print(np.random.choice(range(1000), 10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[767 364 630 279 976 506 114 781   9  23]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tls9LJHbWgVM"
      },
      "source": [
        "!pip3 install transformers numpy torch sklearn\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification, AutoTokenizer\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "%cd 'drive/MyDrive/Internship/Data'\n",
        "\n",
        "file_names = [\"CNNArticles\", \"fb_edit\", \"ireland_headlines\", \"tweets_edited\"]\n",
        "temps = [\"0_5\", \"0_75\", \"1_0\", \"1_25\", \"1_5\"]\n",
        "model_path = \"gpt_classifier\"\n",
        "max_length = 512\n",
        "\n",
        "\n",
        "test_data = pickle.load(open(\"test_data/new_test_data.pkl\", \"rb\"))\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"results/checkpoint-4200\").to(\"cuda\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "def get_prediction(text):\n",
        "\n",
        "    try:\n",
        "\n",
        "      inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    except:\n",
        "\n",
        "      print(text)\n",
        "\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    probs = outputs[0].softmax(1)\n",
        "\n",
        "    return probs.argmax()\n",
        "\n",
        "for t in temps:\n",
        "\n",
        "  x = []\n",
        "  y = []\n",
        "\n",
        "  for f in file_names:\n",
        "\n",
        "      x = test_data[(f,t)][0]\n",
        "      y = list(np.ones(len(test_data[(f,t)][0])))\n",
        "      y_hat = [int(get_prediction(i)) for i in x]\n",
        "\n",
        "      print(accuracy_score(y, y_hat))\n",
        "      print(f)\n",
        "      print(t)\n",
        "      print(\"\\n\")\n",
        "\n",
        "\n",
        "for t in temps:\n",
        "\n",
        "  x = []\n",
        "  y = []\n",
        "\n",
        "  for f in file_names:\n",
        "\n",
        "      x = x + test_data[(f,t)][0]\n",
        "      y = y + list(np.ones(len(test_data[(f,t)][0])))\n",
        "\n",
        "  y_hat = [int(get_prediction(i)) for i in x]\n",
        "\n",
        "  print(accuracy_score(y, y_hat))\n",
        "  print(t)\n",
        "  print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "for f in file_names:\n",
        "\n",
        "    x = test_data[f][0]\n",
        "    y = list(np.zeros(len(test_data[f][0])))\n",
        "\n",
        "    for t in temps:\n",
        "\n",
        "        x = x + test_data[(f,t)][0]\n",
        "        y = y + list(np.ones(len(test_data[(f, t)][0])))\n",
        "\n",
        "\n",
        "# get accuracy by temperature AND datatype\n",
        "\n",
        "test_x = []\n",
        "test_y = []\n",
        "x_length = []\n",
        "\n",
        "\n",
        "for f in file_names:\n",
        "\n",
        "\n",
        "    test_x = test_x + test_data[f][0]\n",
        "    x_length = x_length + test_data[f][1]\n",
        "\n",
        "    test_y = test_y + list(np.zeros(len(test_data[f][0])))\n",
        "\n",
        "    for t in temps:\n",
        "\n",
        "        test_x = test_x + test_data[(f,t)][0]\n",
        "        x_length = x_length + test_data[(f,t)][1]\n",
        "\n",
        "        test_y = test_y + list(np.ones(len(test_data[(f,t)][0])))\n",
        "\n",
        "\n",
        "    # now we have x, y and lengths of x\n",
        "\n",
        "    q1 = np.percentile(x_length, 25)\n",
        "    q2 = np.percentile(x_length, 50)\n",
        "    q3 = np.percentile(x_length, 75)\n",
        "\n",
        "    x1 = [x for i, x in enumerate(test_x) if x_length[i] <= q1]\n",
        "    x2 = [x for i, x in enumerate(test_x) if q1 < x_length[i] <= q2]\n",
        "    x3 = [x for i, x in enumerate(test_x) if q2 < x_length[i] <= q3]\n",
        "    x4 = [x for i, x in enumerate(test_x) if x_length[i] > q3]\n",
        "\n",
        "    y1 = [y for i, y in enumerate(test_y) if x_length[i] <= q1]\n",
        "    y2 = [y for i, y in enumerate(test_y) if q1 < x_length[i] <= q2]\n",
        "    y3 = [y for i, y in enumerate(test_y) if q2 < x_length[i] <= q3]\n",
        "    y4 = [y for i, y in enumerate(test_y) if x_length[i] > q3]\n",
        "\n",
        "    y_hat1 = [int(get_prediction(x)) for x in x1]\n",
        "    y_hat2 = [int(get_prediction(x)) for x in x2]\n",
        "    y_hat3 = [int(get_prediction(x)) for x in x3]\n",
        "    y_hat4 = [int(get_prediction(x)) for x in x4]\n",
        "\n",
        "    print(accuracy_score(y1, y_hat1))\n",
        "    print(q1)\n",
        "    print(accuracy_score(y2, y_hat2))\n",
        "    print(q2)\n",
        "    print(accuracy_score(y3, y_hat3))\n",
        "    print(q3)\n",
        "    print(accuracy_score(y4, y_hat4))\n",
        "\n",
        "    print(f)\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQBVqDl4EzLf"
      },
      "source": [
        "!pip3 install transformers numpy torch sklearn\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification, AutoTokenizer\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "%cd 'drive/MyDrive/Internship/Data'\n",
        "\n",
        "file_names = [\"CNNArticles\", \"fb_edit\", \"ireland_headlines\", \"tweets_edited\"]\n",
        "temps = [\"0_5\", \"0_75\", \"1_0\", \"1_25\", \"1_5\"]\n",
        "model_path = \"gpt_classifier\"\n",
        "max_length = 512\n",
        "\n",
        "\n",
        "test_data = pickle.load(open(\"test_data/new_test_data.pkl\", \"rb\"))\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"results/checkpoint-4200\").to(\"cuda\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "def get_prediction(text):\n",
        "\n",
        "    try:\n",
        "\n",
        "      inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    except:\n",
        "\n",
        "      print(text)\n",
        "\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    probs = outputs[0].softmax(1)\n",
        "\n",
        "    return probs.argmax()\n",
        "\n",
        "# get accuracy by temperature AND datatype\n",
        "\n",
        "test_x = {}\n",
        "test_y = {}\n",
        "x_length = {}\n",
        "\n",
        "q = {}\n",
        "\n",
        "\n",
        "\n",
        "for t in temps:\n",
        "\n",
        "    test_x[t] = []\n",
        "    x_length[t] = []\n",
        "    test_y[t] = []\n",
        "\n",
        "    for f in file_names:\n",
        "\n",
        "        test_x[t] = test_x[t] + test_data[(f,t)][0]\n",
        "        x_length[t] = x_length[t] + test_data[(f,t)][1]\n",
        "\n",
        "        test_y[t] = test_y[t] + list(np.ones(len(test_data[(f,t)][0])))\n",
        "\n",
        "    q[t] = [np.percentile(x_length[t], i) for i in range(0, 100, 10)]\n",
        "\n",
        "print(q)\n",
        "for t in temps:\n",
        "\n",
        "  print(t)\n",
        "\n",
        "  for i in range(1, len(q[t])):\n",
        "\n",
        "    x_ = [x for j, x in enumerate(test_x[t]) if q[t][i-1] < x_length[t][j] <= q[t][i]]\n",
        "    y_ = [y for j, y in enumerate(test_y[t]) if q[t][i-1] < x_length[t][j] <= q[t][i]]\n",
        "\n",
        "    y_hat = [int(get_prediction(x)) for x in x_]\n",
        "\n",
        "    print(accuracy_score(y_, y_hat))\n",
        "\n",
        "  print(\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyzoqqWnYUUH"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "%cd 'drive/MyDrive/Internship/Data'\n",
        "\n",
        "# convert test data to form with length attached\n",
        "\n",
        "with open(\"test_data/test_data.pkl\", \"rb\") as f:\n",
        "\n",
        "  test_data = pickle.load(f)\n",
        "\n",
        "new_test_data = {}\n",
        "\n",
        "for k in test_data.keys():\n",
        "\n",
        "   text = list(test_data[k].iloc[:, 0])\n",
        "   text = [str(x) for x in text]\n",
        "   length = [len(x) for x in text]\n",
        "   new_test_data[k] = [text, length]\n",
        "\n",
        "   print(type(new_test_data[k][0]))\n",
        "\n",
        "   print(new_test_data[k][0][0:10])\n",
        "   print(new_test_data[k][1][0:10])\n",
        "\n",
        "with open(\"test_data/new_test_data.pkl\", \"wb\") as f:\n",
        "\n",
        "  pickle.dump(new_test_data, f)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}